#
# Build this SIF into /home/$USER/scratch/group1/appainter/appainter.sif to avoid filling the projects/home quota.

Bootstrap: docker
From: nvidia/cuda:12.2.0-devel-ubuntu22.04

%labels
    Maintainer You
    Version 1.1
    Description "Minimal DeepSpeed + PyTorch + HF + Nsight Systems container for multi-node inference"

%environment
    # Ensure CUDA & NCCL show up correctly
    export LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH
    export PATH=/opt/nsight-systems/bin:$PATH

    # Expose bind-mounted images
    export PYTHONPATH=/ext/pytorch/lib/python3.10/site-packages:$PYTHONPATH
    export PATH=/ext/gromacs/bin:$PATH

    # Avoid HF cache warnings
    export HF_HOME=/workspace/hf_cache

    # Ensure Python finds /app
    export PYTHONPATH=/app:$PYTHONPATH

%post
    apt-get update && apt-get install -y --no-install-recommends \
        python3 python3-pip python3-dev \
        git \
        curl \
        wget \
        libaio1 \
        openssh-client \
        unzip \
        build-essential

    pip install --upgrade pip wheel setuptools

    # DeepSpeed inferenceâ€“only install (no torch available at build time)
    export DS_BUILD_OPS=0
    export DS_SKIP_CUDA_CHECK=1
    export DS_SKIP_TORCH_CHECK=1

    # Install with no dependencies so torch isnt pulled
    pip install --no-deps deepspeed

    # Hugging Face stack, no dependencies to minimize size
    pip install --no-deps transformers tokenizers sentencepiece accelerate

    # Install the public Nsight Systems debian package
    wget https://developer.download.nvidia.com/devtools/nsight-systems/NsightSystems-linux-cli-public-2024.1.1.59-3380207.deb -O /tmp/nsys.deb
    apt-get update
    apt-get install -y /tmp/nsys.deb

    mkdir -p /app

%files
    src/run_distributed_inference.py /app/run_distributed_inference.py
    slurm/run.sh /app/run.sh

%runscript
    exec python3 /app/run_distributed_inference.py "$@"
